"use strict";(globalThis.webpackChunk_001_physical_ai_textbook_docs=globalThis.webpackChunk_001_physical_ai_textbook_docs||[]).push([[1963],{3486:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>c,contentTitle:()=>t,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>a});const s=JSON.parse('{"id":"module2-robot-sensing-and-perception/outline","title":"Module 2: Robot Sensing and Perception","description":"1. Introduction to Robot Sensing","source":"@site/docs/module2-robot-sensing-and-perception/outline.md","sourceDirName":"module2-robot-sensing-and-perception","slug":"/module2-robot-sensing-and-perception/outline","permalink":"/docs/module2-robot-sensing-and-perception/outline","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module2-robot-sensing-and-perception/outline.md","tags":[],"version":"current","frontMatter":{}}');var l=i(4848),r=i(8453);const o={},t="Module 2: Robot Sensing and Perception",c={},a=[{value:"1. Introduction to Robot Sensing",id:"1-introduction-to-robot-sensing",level:2},{value:"2. Vision Systems",id:"2-vision-systems",level:2},{value:"3. Lidar and Radar",id:"3-lidar-and-radar",level:2},{value:"4. Force and Torque Sensors",id:"4-force-and-torque-sensors",level:2},{value:"5. Proprioceptive Sensors",id:"5-proprioceptive-sensors",level:2},{value:"6. Sensor Fusion",id:"6-sensor-fusion",level:2},{value:"7. Perception Algorithms",id:"7-perception-algorithms",level:2},{value:"8. Challenges in Robot Perception",id:"8-challenges-in-robot-perception",level:2},{value:"9. Future Trends in Sensing",id:"9-future-trends-in-sensing",level:2}];function d(n){const e={h1:"h1",h2:"h2",header:"header",li:"li",ul:"ul",...(0,r.R)(),...n.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(e.header,{children:(0,l.jsx)(e.h1,{id:"module-2-robot-sensing-and-perception",children:"Module 2: Robot Sensing and Perception"})}),"\n",(0,l.jsx)(e.h2,{id:"1-introduction-to-robot-sensing",children:"1. Introduction to Robot Sensing"}),"\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsxs)(e.li,{children:["Importance of Perception in Robotics","\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"Enabling autonomous behavior"}),"\n",(0,l.jsx)(e.li,{children:"Interacting with the environment"}),"\n",(0,l.jsx)(e.li,{children:"Decision making"}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(e.li,{children:["Overview of Different Types of Sensors","\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"Contact vs. Non-contact sensors"}),"\n",(0,l.jsx)(e.li,{children:"Active vs. Passive sensors"}),"\n",(0,l.jsx)(e.li,{children:"Internal vs. External sensors"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(e.h2,{id:"2-vision-systems",children:"2. Vision Systems"}),"\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsxs)(e.li,{children:["Cameras","\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"Monocular Cameras: Principles, applications, limitations"}),"\n",(0,l.jsx)(e.li,{children:"Stereo Cameras: Depth perception, triangulation, disparity maps"}),"\n",(0,l.jsx)(e.li,{children:"Depth Cameras (e.g., ToF, Structured Light): Principles, advantages, limitations"}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(e.li,{children:["Image Processing Fundamentals","\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"Image representation (pixels, color spaces)"}),"\n",(0,l.jsx)(e.li,{children:"Basic operations: filtering, enhancement, edge detection"}),"\n",(0,l.jsx)(e.li,{children:"Morphological operations"}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(e.li,{children:["Feature Extraction","\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"Corners, blobs, edges"}),"\n",(0,l.jsx)(e.li,{children:"Feature descriptors (e.g., SIFT, SURF, ORB)"}),"\n",(0,l.jsx)(e.li,{children:"Applications in object recognition and tracking"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(e.h2,{id:"3-lidar-and-radar",children:"3. Lidar and Radar"}),"\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsxs)(e.li,{children:["Lidar (Light Detection and Ranging)","\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"Principles: Time-of-flight, laser scanning"}),"\n",(0,l.jsx)(e.li,{children:"Applications: Mapping, localization (SLAM), obstacle avoidance"}),"\n",(0,l.jsx)(e.li,{children:"Point Cloud Data Processing: Filtering, segmentation, registration"}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(e.li,{children:["Radar (Radio Detection and Ranging)","\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"Principles: Doppler effect, electromagnetic waves"}),"\n",(0,l.jsx)(e.li,{children:"Applications: Long-range detection, adverse weather conditions"}),"\n",(0,l.jsx)(e.li,{children:"Comparison with Lidar: Strengths and weaknesses"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(e.h2,{id:"4-force-and-torque-sensors",children:"4. Force and Torque Sensors"}),"\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsxs)(e.li,{children:["Principles of Force and Torque Measurement","\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"Strain gauges, piezoelectric sensors"}),"\n",(0,l.jsx)(e.li,{children:"Multi-axis force/torque sensors"}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(e.li,{children:["Applications","\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:'Haptic Feedback: Enabling robots to "feel"'}),"\n",(0,l.jsx)(e.li,{children:"Manipulation: Grasping, object handling, assembly"}),"\n",(0,l.jsx)(e.li,{children:"Human-Robot Interaction: Safety, collaborative tasks"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(e.h2,{id:"5-proprioceptive-sensors",children:"5. Proprioceptive Sensors"}),"\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsxs)(e.li,{children:["Encoders","\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"Rotary and Linear Encoders: Principles, types (absolute, incremental)"}),"\n",(0,l.jsx)(e.li,{children:"Applications: Joint position sensing, motor control"}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(e.li,{children:["Inertial Measurement Units (IMUs)","\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"Accelerometers: Measuring linear acceleration"}),"\n",(0,l.jsx)(e.li,{children:"Gyroscopes: Measuring angular velocity"}),"\n",(0,l.jsx)(e.li,{children:"Magnetometers: Measuring magnetic field (for orientation)"}),"\n",(0,l.jsx)(e.li,{children:"Applications: Robot orientation, balance, navigation"}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(e.li,{children:["Joint Position Sensing","\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"Potentiometers, resolvers"}),"\n",(0,l.jsx)(e.li,{children:"Feedback in robotic arms and manipulators"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(e.h2,{id:"6-sensor-fusion",children:"6. Sensor Fusion"}),"\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsxs)(e.li,{children:["Concept and Importance","\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"Combining data from multiple sensors"}),"\n",(0,l.jsx)(e.li,{children:"Overcoming individual sensor limitations"}),"\n",(0,l.jsx)(e.li,{children:"Improving robustness and accuracy"}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(e.li,{children:["Techniques for Sensor Fusion","\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"Kalman Filters: Principles, Extended Kalman Filter (EKF), Unscented Kalman Filter (UKF)"}),"\n",(0,l.jsx)(e.li,{children:"Particle Filters"}),"\n",(0,l.jsx)(e.li,{children:"Complementary Filters"}),"\n",(0,l.jsx)(e.li,{children:"Probabilistic approaches"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(e.h2,{id:"7-perception-algorithms",children:"7. Perception Algorithms"}),"\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsxs)(e.li,{children:["Object Detection","\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"Traditional methods (e.g., Viola-Jones)"}),"\n",(0,l.jsx)(e.li,{children:"Deep Learning-based methods (e.g., R-CNN, YOLO, SSD)"}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(e.li,{children:["Object Tracking","\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"Kalman filters, particle filters"}),"\n",(0,l.jsx)(e.li,{children:"Deep SORT, SORT"}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(e.li,{children:["Segmentation","\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"Semantic Segmentation: Pixel-level classification"}),"\n",(0,l.jsx)(e.li,{children:"Instance Segmentation: Detecting and segmenting individual objects"}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(e.li,{children:["Pose Estimation","\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"Estimating 6D pose (position and orientation) of objects"}),"\n",(0,l.jsx)(e.li,{children:"Applications in manipulation and navigation"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(e.h2,{id:"8-challenges-in-robot-perception",children:"8. Challenges in Robot Perception"}),"\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsxs)(e.li,{children:["Sensor Noise and Uncertainty","\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"Sources of noise"}),"\n",(0,l.jsx)(e.li,{children:"Techniques for noise reduction"}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(e.li,{children:["Occlusion","\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"Partial and full occlusion"}),"\n",(0,l.jsx)(e.li,{children:"Strategies for handling occluded objects"}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(e.li,{children:["Varying Lighting Conditions","\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"Impact on vision systems"}),"\n",(0,l.jsx)(e.li,{children:"Techniques for robust perception in different lighting"}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(e.li,{children:["Dynamic Environments","\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"Dealing with moving objects and changing scenes"}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(e.li,{children:["Computational Constraints","\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"Real-time processing requirements"}),"\n",(0,l.jsx)(e.li,{children:"Optimization of perception algorithms"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(e.h2,{id:"9-future-trends-in-sensing",children:"9. Future Trends in Sensing"}),"\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsxs)(e.li,{children:["Advanced Sensor Technologies","\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"Event cameras"}),"\n",(0,l.jsx)(e.li,{children:"Hyperspectral imaging"}),"\n",(0,l.jsx)(e.li,{children:"Tactile sensors with high resolution"}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(e.li,{children:["AI-driven Perception","\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"End-to-end learning for perception"}),"\n",(0,l.jsx)(e.li,{children:"Reinforcement learning for active sensing"}),"\n",(0,l.jsx)(e.li,{children:"Generative models for perception enhancement"}),"\n"]}),"\n"]}),"\n"]})]})}function h(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,l.jsx)(e,{...n,children:(0,l.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>o,x:()=>t});var s=i(6540);const l={},r=s.createContext(l);function o(n){const e=s.useContext(r);return s.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function t(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(l):n.components||l:o(n.components),s.createElement(r.Provider,{value:e},n.children)}}}]);